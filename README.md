# Awesome Human Action Recognition üî•

A curated list of Human Action Recognition (HAR) projects, papers, and codes, organized by methods and datasets.

Êú¨‰ªìÂ∫ìÁî®‰∫éÊï¥ÁêÜ Human Action Recognition Áõ∏ÂÖ≥ÁöÑÂºÄÊ∫êÈ°πÁõÆÔºåÊñπ‰æøÂø´ÈÄüÊü•ÈòÖ‰∏éÂ≠¶‰π†„ÄÇ

---

## üìÇ Table of Contents

- [1. Transformer-based Methods](#1-transformer-based-methods)
- [2. 3D CNN-based Methods](#2-3d-cnn-based-methods)
- [3. Skeleton-based Methods](#3-skeleton-based-methods)
- [4. Self-supervised Learning](#4-self-supervised-learning)
- [5. Datasets & Benchmarks](#5-datasets--benchmarks)

---

## 1. Transformer-based Methods

- [pairDETR (CVPR 2024)](https://github.com/mts-ai/pairdetr)
- [DualDETR (CVPR 2024)](https://github.com/MCG-NJU/DualDETR)
- [LART (CVPR 2023)](https://people.eecs.berkeley.edu/~jathushan/LART/)
- [STEP-CATFormer(BMVC 2023](https://github.com/maclong01/STEP-CATFormer)
- [STAR(WACV 2023)](https://openaccess.thecvf.com/content/WACV2023/html/Ahn_STAR-Transformer_A_Spatio-Temporal_Cross_Attention_Transformer_for_Human_Action_Recognition_WACV_2023_paper.html)
- [ActionFormer (ECCV 2022)](https://github.com/happyharrycn/actionformer_release)  
- [TimesFormer (NeurIPS 2021)](https://github.com/facebookresearch/TimeSformer)  
- [3Mformer(CVPR 2023)](https://openaccess.thecvf.com//content/CVPR2023/html/Wang_3Mformer_Multi-Order_Multi-Mode_Transformer_for_Skeletal_Action_Recognition_CVPR_2023_paper.html)
- [MS-TCT (CVPR 2022)](https://github.com/dairui01/MS-TCT)
- [OadTR (ICCV 2021)](https://github.com/wangxiang1230/OadTR)
- [STAR](https://github.com/cunjunyu/STAR)
- [GraphTransformer](https://github.com/graphdeeplearning/graphtransformer)
- [SKateFormer](https://kaist-viclab.github.io/SkateFormer_site/)
- [GraFormer](https://github.com/Graformer/GraFormer)
---

## 2. 3D CNN-based Methods

- [PoseConv3D (CVPR 2022)](https://github.com/kennymckormick/pyskl)  


---

## 3. Skeleton-based Methods
- [blockGCN (CVPR 2024)](https://github.com/ZhouYuxuanYX/BlockGCN)
- [HD-GCN (ICCV 2023)](https://github.com/Jho-Yonsei/HD-GCN)
- [POOPMAN(CVPR 2023)](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Neural_Koopman_Pooling_Control-Inspired_Temporal_Dynamics_Encoding_for_Skeleton-Based_Action_CVPR_2023_paper.html)
- [ST-GCN (AAAI 2018)](https://github.com/yysijie/st-gcn)  
- [infokGCN (CVPR 2022)](https://github.com/stnoah1/infogcn)
- [AdsSGN(ICCV 2021)](https://github.com/lshiwjx/AdaSGN)
- [CTR-GCN (CVPR 2021)](https://github.com/UshioX/CTR-GCN)  
- [Shift-GCN (CVPR 2020)](https://github.com/kchengiva/Shift-GCN)  
- [DeGCN (2021)](https://ieeexplore.ieee.org/abstract/document/10478824?casa_token=fuWV-WNVjq8AAAAA:TcXyXzawfn5djFzmmEQrkzvGJcAVvHOSGJxoItpfDBhu-Z5EHos7-5AI0eT_OWjR2Cf605hyiw0)
- [SGN (CVPR 2020)](https://github.com/microsoft/SGN)
- [DC-GCN(ECCV 2020)](https://github.com/kchengiva/DecoupleGCN-DropGraph)
- [Extended Multi-stream Temporal-attention Module for Skeletonbased Human Action Recognition (HAR)](https://www.sciencedirect.com/science/article/abs/pii/S0747563224003509)
- [Are Spatial-Temporal Graph Convolution Networks for Human Action Recognition Over-Parameterized?(2025.5.15)](https://github.com/davelailai/Sparse-ST-GCN)
- [A Generically Contrastive Spatiotemporal RepresentationEnhancement for 3D Skeleton Action Recognition (2025.3.17)](https://github.com/zhshj0110/CSRE)
- [High-Performance Inference Graph Convolutional Networks for Skeleton-Based Action Recognition(2025.1.7)](https://github.com/lizaowo/HPI-GCN)
- [Revealing Key Details to See Differences: A Novel Prototypical Perspective for Skeleton-based Action Recognition(2025.3.20)](https://github.com/firework8/ProtoGCN)
- [SkeletonX: Data-Efficient Skeleton-based Action Recognition via Cross-sample Feature Aggregation(2025.4.16)](https://github.com/zzysteve/SkeletonX)
--

## 4. Self-supervised Learning

- [ActCLR (CVPR 2023)](https://github.com/GuangmingZhu/ActCLR)
- [STG-NF (ICCV 2023)](https://github.com/orhir/STG-NF)
- [AimCLR (AAAI 2022)](https://github.com/Levigty/AimCLR)
 
---

## 5. others

-[STMT (CVPR 2023)](https://github.com/zgzxy001/STMT)
-[MULE (CVPR 2023)](https://github.com/charliezhaoyinpeng/mule)  
-[LPR Memory (ICCV 2021)](https://openaccess.thecvf.com/content/ICCV2021/html/Kim_Robust_Small-Scale_Pedestrian_Detection_With_Cued_Recall_via_Memory_Learning_ICCV_2021_paper.html)
-[KShapeNet (ICCV 2021)](https://openaccess.thecvf.com/content/ICCV2021/html/Friji_Geometric_Deep_Neural_Network_Using_Rigid_and_Non-Rigid_Transformations_for_ICCV_2021_paper.html)
-[Graph-mamba](https://github.com/bowang-lab/Graph-Mamba)
-[MambaVision(CVPR 2025)](https://github.com/NVlabs/MambaVision)
-[MobileMamba(CVPR 2025)](https://github.com/lewandofskee/MobileMamba)
-[SAMBA(ICLR 2025)](https://github.com/microsoft/Samba)

---

## 6. Datasets & Benchmarks

- [Kinetics](https://deepmind.com/research/open-source/kinetics) 
- [NTU RGB+D](https://rose1.ntu.edu.sg/dataset/actionRecognition/) 
- [UCF101](https://www.crcv.ucf.edu/data/UCF101.php) 

---




